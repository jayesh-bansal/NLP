{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jayesh-bansal/NLP/blob/main/Lab_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# WORD REPRESENTATION"
      ],
      "metadata": {
        "id": "-xzW4iEI4u4Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0kLwp7Huah3",
        "outputId": "617069a9-4817-45b4-ee55-0d3b7d908029"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n"
          ]
        }
      ],
      "source": [
        "#Installing the Required Files\n",
        "!pip install scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing the Count2Vec and ,TfidVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
      ],
      "metadata": {
        "id": "pGB6Uaj_umgS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#These is the todays text iam going to use,\n",
        "text = [\"Currently Iam learning about tokenization and vectorization.\",\n",
        "        \"Tokenization is the process of breaking text into smaller pieces\"\n",
        "        \"And these Vectorization is just like counting the Frequency or may be counting the density\",\n",
        "        \"but when i googled it it says Word2vec is a technique in natural language processing (NLP) that obtains vector representations of words1.\",\n",
        "        \"And i don't know about these TfidfVectorizer but i googled and found that Inverse Document Frequency (IDF) is a statistical measure used to evaluate how important a word is to a document in a collection or corpus\",\n",
        "        \"It is one of the key concepts in the Term Frequency-Inverse Document Frequency (TF-IDF) weighting scheme, which is widely used in information retrieval and text mining. \"]"
      ],
      "metadata": {
        "id": "PpnRRpdjuq1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Count Vectorization Representation\n",
        "count_vect = CountVectorizer()\n",
        "count_vector = count_vect.fit_transform(text)\n",
        "\n",
        "print(\"Count vector representation: \",count_vector.toarray())\n",
        "print(\"Feature Names:\",count_vect.get_feature_names_out())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2I5u7sCu_9d",
        "outputId": "7addef15-6a26-48bd-ffb7-b6b2e83c4e00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Count vector representation:  [[1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0]\n",
            " [0 0 1 1 0 0 0 0 2 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 2 0 1 0 0 0 0 1 1 0 0\n",
            "  0 0 0 1 0 1 1 1 0 0 0 0 0 1 0 0 0 1 0 0 0 3 1 0 1 0 0 1 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 2 0 0 0 1 0 0 0 0 0\n",
            "  1 1 1 1 0 0 0 0 1 1 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 1 1]\n",
            " [1 2 0 0 1 1 0 1 0 0 0 2 1 1 1 1 1 1 0 1 1 1 0 0 1 2 0 0 0 1 0 0 0 0 1 0\n",
            "  0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 1 2 0 1 0 0 0 0 0 0 1 0 0]\n",
            " [0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 2 0 0 0 1 0 2 1 0 1 2 1 0 1 0 0 0 0 0 0 1\n",
            "  0 0 0 1 1 0 0 0 0 0 1 0 1 0 0 0 1 1 1 0 0 2 0 0 0 1 0 0 1 0 1 1 0 0 0]]\n",
            "Feature Names: ['about' 'and' 'be' 'breaking' 'but' 'collection' 'concepts' 'corpus'\n",
            " 'counting' 'currently' 'density' 'document' 'don' 'evaluate' 'found'\n",
            " 'frequency' 'googled' 'how' 'iam' 'idf' 'important' 'in' 'information'\n",
            " 'into' 'inverse' 'is' 'it' 'just' 'key' 'know' 'language' 'learning'\n",
            " 'like' 'may' 'measure' 'mining' 'natural' 'nlp' 'obtains' 'of' 'one' 'or'\n",
            " 'piecesand' 'process' 'processing' 'representations' 'retrieval' 'says'\n",
            " 'scheme' 'smaller' 'statistical' 'technique' 'term' 'text' 'tf'\n",
            " 'tfidfvectorizer' 'that' 'the' 'these' 'to' 'tokenization' 'used'\n",
            " 'vector' 'vectorization' 'weighting' 'when' 'which' 'widely' 'word'\n",
            " 'word2vec' 'words1']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_vect = TfidfVectorizer()\n",
        "tfid_vector = tfidf_vect.fit_transform(text)\n",
        "print(\"TFIDF vector representation: \",tfid_vector.toarray())\n",
        "print(\"Feature Names:\",tfidf_vect.get_feature_names_out())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1g63NgAwErJ",
        "outputId": "9dea1b91-6571-48bb-bef8-000fe874cfe3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TFIDF vector representation:  [[0.40301621 0.40301621 0.         0.         0.         0.\n",
            "  0.40301621 0.         0.         0.         0.40301621 0.\n",
            "  0.         0.         0.         0.         0.         0.40301621\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.30650422 0.         0.30650422 0.         0.         0.        ]\n",
            " [0.         0.         0.17946411 0.17946411 0.         0.35892823\n",
            "  0.         0.17946411 0.17946411 0.         0.         0.\n",
            "  0.17946411 0.27297417 0.         0.17946411 0.         0.\n",
            "  0.17946411 0.17946411 0.         0.         0.         0.13648708\n",
            "  0.17946411 0.17946411 0.17946411 0.         0.         0.\n",
            "  0.17946411 0.         0.17946411 0.         0.53839234 0.17946411\n",
            "  0.13648708 0.         0.13648708 0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.21740775 0.\n",
            "  0.         0.         0.         0.21740775 0.         0.21740775\n",
            "  0.         0.1653442  0.4348155  0.         0.21740775 0.\n",
            "  0.         0.         0.21740775 0.21740775 0.21740775 0.1653442\n",
            "  0.         0.         0.         0.21740775 0.21740775 0.21740775\n",
            "  0.         0.21740775 0.         0.21740775 0.         0.\n",
            "  0.         0.21740775 0.         0.21740775 0.21740775 0.21740775]]\n",
            "Feature Names: ['about' 'and' 'be' 'breaking' 'but' 'counting' 'currently' 'density'\n",
            " 'frequency' 'googled' 'iam' 'in' 'into' 'is' 'it' 'just' 'language'\n",
            " 'learning' 'like' 'may' 'natural' 'nlp' 'obtains' 'of' 'or' 'piecesand'\n",
            " 'process' 'processing' 'representations' 'says' 'smaller' 'technique'\n",
            " 'text' 'that' 'the' 'these' 'tokenization' 'vector' 'vectorization'\n",
            " 'when' 'word2vec' 'words1']\n"
          ]
        }
      ]
    }
  ]
}